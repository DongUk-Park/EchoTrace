import os
import json
import gzip
import pickle
from collections import defaultdict
from tqdm import tqdm
import argparse

from main import allmrec
from pre_train.sasrec.main import sasrec_main
from models.a_llmrec_model import *
import difflib


def load_train_dict_from_txt(train_file_path):
    train_dict = defaultdict(list)
    with open(train_file_path, 'r') as f:
        for line in f:
            user, item = map(int, line.strip().split())
            train_dict[user].append(item)
    return train_dict


def call_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--multi_gpu", action='store_true')
    parser.add_argument('--gpu_num', type=int, default=0)
    parser.add_argument("--llm", type=str, default='opt', help='opt, llama')
    parser.add_argument("--recsys", type=str, default='sasrec')
    parser.add_argument("--rec_pre_trained_data", type=str, default='ml-100k')
    parser.add_argument('--batch_size1', default=32, type=int)
    parser.add_argument('--batch_size2', default=2, type=int)
    parser.add_argument('--batch_size_infer', default=2, type=int)
    parser.add_argument('--maxlen', default=50, type=int)
    parser.add_argument('--num_epochs', default=10, type=int)
    parser.add_argument("--stage1_lr", type=float, default=0.0001)
    parser.add_argument("--stage2_lr", type=float, default=0.0001)
    parser.add_argument('--topN', type=int, default=5)  # ğŸ”¹ ì‚¬ìš©ìë‹¹ ì¶”ì²œ ê°œìˆ˜
    args = parser.parse_args()

    print(f"device num : {args.gpu_num}")
    args.device = 'cuda:' + str(args.gpu_num)
    args.rec_pre_trained_data = "ml-100k"
    return args


if __name__ == "__main__":
    data_path   = "/home/parkdw00/Codes/A-LLMRec/data/amazon"
    result_path = "/home/parkdw00/Codes/A-LLMRec"
    train_txt_path = os.path.join(data_path, 'ml-100k.txt')
    predict_json_path = os.path.join(result_path, "recommend_all_users_filter_bubble_check.json")

    args = call_args()

    # 0) ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ë¡œë“œ
    train_dict = load_train_dict_from_txt(train_txt_path)

    # 1) ì „ì²˜ë¦¬/í•™ìŠµ: SASRec â†’ ALLMRec phase1/2 (ê° 1íšŒ)
    #    (í•„ìš” ì—†ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥)
    sasrec_main()
    allmrec(args, phase=1)
    allmrec(args, phase=2)

    # 2) ì¶”ë¡  ì¤€ë¹„: ëª¨ë¸ ë¡œë“œ (phase1/2 ì²´í¬í¬ì¸íŠ¸)
    args.phase = 3
    model = A_llmrec_model(args).to(args.device)
    model.load_model(args, phase1_epoch=10, phase2_epoch=5)

    # 3) íƒ€ì´í‹€â†”ID ë§¤í•‘ ë¡œë“œ
    with gzip.open(os.path.join(data_path, "ml-100k_text_name_dict.json.gz"), "rb") as f:
        name_dict = pickle.load(f)
    title2id = {v.lower(): k for k, v in name_dict["title"].items()}
    known_titles = list(title2id.keys())

    # 4) ì „ ìœ ì € ì¶”ì²œ ìƒì„± (í”¼ë“œë°± ì—…ë°ì´íŠ¸/ë¶„í•  ì—†ìŒ)
    all_predict = defaultdict(list)
    for u_id in tqdm(train_dict.keys(), desc="Recommending for all users"):
        user_train = train_dict.get(u_id, [])
        if not user_train:
            continue
        
        existing_ids = set()  # ì´ë²ˆ ìœ ì € ì¶”ì²œ ë‚´ ì¤‘ë³µ ë°©ì§€
        tries_per_rec = 5      # ê° ì¶”ì²œ 1ê°œ ë‹¹ ìµœëŒ€ ì‹œë„ íšŸìˆ˜
        banned_ids = list(set(user_train))
        for _ in range(args.topN):
            # ìµœëŒ€ tries_per_rec ë²ˆ ì‹œë„í•´ì„œ ìƒˆë¡œìš´ ì•„ì´í…œ í™•ë³´
            got_one = False
            for _try in range(tries_per_rec):
                pred_title = allmrec(args, phase=3, user_id=u_id, user_train=user_train, user_gt = banned_ids,model=model)
                if not isinstance(pred_title, str) or not pred_title.strip():
                    continue

                tl = pred_title.strip().lower()

                # case1: ì •í™• ë§¤ì¹­
                if tl in title2id:
                    pid = title2id[tl]
                    if (pid not in user_train) and (pid not in existing_ids):
                        #all_predict[u_id].append(pred_title.strip())
                        all_predict[u_id].append(pid)
                        existing_ids.add(pid)
                        got_one = True
                        break
                    else:
                        continue

                # case2: í¼ì§€ ë§¤ì¹­ (ì›í•˜ë©´ ì‚¬ìš©)
                matches = difflib.get_close_matches(tl, known_titles, n=1, cutoff=0.90)
                if matches:
                    mt = matches[0]
                    pid = title2id[mt]
                    if (pid not in user_train) and (pid not in existing_ids):
                        # í‘œê¸° ì¼ê´€ì„±: ì›ë¬¸ìœ¼ë¡œ ë³µì›
                        canonical = name_dict["title"][pid]
                        #all_predict[u_id].append(canonical)
                        all_predict[u_id].append(pid)
                        existing_ids.add(pid)
                        got_one = True
                        break
                else:
                    continue

            # ë§Œì•½ ì´ë²ˆ ìŠ¬ë¡¯ì—ì„œ ìƒˆ ì•„ì´í…œì„ ëª» ì–»ì—ˆìœ¼ë©´ íŒ¨ìŠ¤(ë¹„ì›Œë‘ )

    # 5) ê²°ê³¼ ì €ì¥
    with open(predict_json_path, "w") as f:
        json.dump({int(k): v for k, v in all_predict.items()}, f, indent=2)

    print(f"âœ… Done. Saved recommendations to: {predict_json_path}")
